{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad25292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../FILIMDB/train.texts', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read().split('\\n')\n",
    "    \n",
    "with open('../FILIMDB/train.labels', 'r', encoding='utf-8') as f:\n",
    "    labels = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b4c82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15001, 15001)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0b78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list(zip(texts, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90d7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list(filter(lambda x: x[1] == 'pos', train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd258017",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = list(filter(lambda x: x[1] == 'neg', train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c94d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min, max, mean, median\n",
    "from statistics import mean, median\n",
    "\n",
    "def calc_stats(texts_and_labels):\n",
    "    len_s = [len(text) for text, label in texts_and_labels]\n",
    "    return min(len_s), max(len_s), mean(len_s), median(len_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b895e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min=70, max=10363, mean=1360.8021276595746, median=996.5\n"
     ]
    }
   ],
   "source": [
    "print('min={0}, max={1}, mean={2}, median={3}'.format(*calc_stats(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d31a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min=52, max=8969, mean=1316.3576203208556, median=981.0\n"
     ]
    }
   ],
   "source": [
    "print('min={0}, max={1}, mean={2}, median={3}'.format(*calc_stats(neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14a01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63827cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    except_list = \".?!\"\n",
    "    p = re.compile(fr\"[^\\w'+{except_list}+']\")\n",
    "    \n",
    "    tokens = p.split(text.lower())\n",
    "    return list(filter(None, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c53ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokenized = [tokenize(text) for text, label in pos]\n",
    "neg_tokenized = [tokenize(text) for text, label in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312de7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0b144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "pos_tokenized = list(itertools.chain.from_iterable(pos_tokenized))\n",
    "neg_tokenized = list(itertools.chain.from_iterable(neg_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a94cd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counter = Counter(pos_tokenized)\n",
    "neg_counter = Counter(neg_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311fd34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cute.',\n",
       " 'mall.',\n",
       " \"bear's\",\n",
       " 'mail.',\n",
       " 'basketball',\n",
       " 'laughs',\n",
       " 'film!!',\n",
       " 'insp.',\n",
       " 'been',\n",
       " 'sumptuous',\n",
       " 'solomon',\n",
       " '2002',\n",
       " 'bugged',\n",
       " 'perverted.',\n",
       " 'cillian',\n",
       " 'aborigines',\n",
       " 'conniving',\n",
       " 'gun!',\n",
       " 'hart',\n",
       " 'diplomacy',\n",
       " 'claire',\n",
       " 'pour',\n",
       " 'vivian',\n",
       " 'dim.',\n",
       " 'flinty',\n",
       " 'policies',\n",
       " 'rochester',\n",
       " 'concorde',\n",
       " 'ph.d',\n",
       " 'incapable',\n",
       " 'laughable',\n",
       " 'quota',\n",
       " 'boil',\n",
       " 'heirs',\n",
       " 'negligent',\n",
       " 'boo',\n",
       " 'manager',\n",
       " 'fortunate',\n",
       " 'delinquent',\n",
       " 'lina',\n",
       " 'executives',\n",
       " 'risk',\n",
       " 'martinez',\n",
       " 'longing',\n",
       " 'duplicity',\n",
       " \"lindsey's\",\n",
       " 'deconstruct',\n",
       " 'cannonball',\n",
       " 'accomplishment.',\n",
       " 'walsh',\n",
       " 'of...its',\n",
       " 'robbie',\n",
       " 'bollywood',\n",
       " 'thunder',\n",
       " \"armstrong's\",\n",
       " 'coordinators',\n",
       " 'relentless.',\n",
       " 'columbian',\n",
       " 'betrays',\n",
       " 'chong',\n",
       " 'illiterate',\n",
       " 'linguist',\n",
       " 'orchestrating',\n",
       " 'cruises',\n",
       " 'rats.',\n",
       " 'inclusive',\n",
       " 'pranks.',\n",
       " 'archives',\n",
       " 'links',\n",
       " 'proclamations',\n",
       " \"teenager's\",\n",
       " 'stout',\n",
       " 'imprison',\n",
       " 'idol.',\n",
       " '112',\n",
       " 'drilled',\n",
       " 'twilight',\n",
       " 'intruder',\n",
       " 'zizek',\n",
       " 'dennehy',\n",
       " 'title.',\n",
       " \"we've\",\n",
       " 'failed?',\n",
       " 'tricking',\n",
       " 'shape!',\n",
       " 'react',\n",
       " 'dumpy',\n",
       " 'contents',\n",
       " 'lulu',\n",
       " 'dwindles',\n",
       " 'knows...',\n",
       " 'azkaban',\n",
       " 'charlton',\n",
       " 'man.',\n",
       " 'r2',\n",
       " 'bus',\n",
       " 'interior',\n",
       " 'esther',\n",
       " 'nightingale',\n",
       " 'stuffing',\n",
       " 'debates',\n",
       " 'premature',\n",
       " 'nearly',\n",
       " 'neff',\n",
       " 'jesus!',\n",
       " 'aways',\n",
       " 'slice',\n",
       " 'groomed',\n",
       " 'tape.',\n",
       " 'progress',\n",
       " 'poe.',\n",
       " 'rode',\n",
       " 'indie.',\n",
       " 'cues',\n",
       " 'cavanagh',\n",
       " 'merchant',\n",
       " 'rejected.',\n",
       " 'depardieu',\n",
       " 'nguyen',\n",
       " 'conclusion',\n",
       " '3po',\n",
       " 'antagonizes',\n",
       " 'mailbox',\n",
       " 'glue',\n",
       " 'plaudits',\n",
       " 'debra',\n",
       " 'bull',\n",
       " 'positive.',\n",
       " 'consulted',\n",
       " 'motherhood',\n",
       " 'reel.',\n",
       " 'short',\n",
       " 'cheapies',\n",
       " 'made.',\n",
       " 'angst',\n",
       " \"directors'\",\n",
       " 'springer',\n",
       " \"'gritty'\",\n",
       " 'valiantly',\n",
       " 'hawaii.',\n",
       " 'forrest',\n",
       " 'foxx',\n",
       " 'blur',\n",
       " 'cusack',\n",
       " 'arms.',\n",
       " 'leads',\n",
       " 'microcosm',\n",
       " 'define',\n",
       " 'buxom',\n",
       " \"hero'\",\n",
       " 'chess',\n",
       " '93',\n",
       " 'on',\n",
       " 'progression',\n",
       " 'flashlight',\n",
       " 'robotech',\n",
       " 'foreigner',\n",
       " 'cgi.',\n",
       " 'key',\n",
       " 'springsteen',\n",
       " 'warn',\n",
       " 'dock',\n",
       " 'um',\n",
       " 'inundated',\n",
       " 'revisits',\n",
       " 'be.',\n",
       " 'visionaries',\n",
       " 'warming',\n",
       " 'dry.',\n",
       " 'thoughts.',\n",
       " \"generation'\",\n",
       " 'sexless',\n",
       " 'country.',\n",
       " 'purists',\n",
       " 'crouching',\n",
       " 'shared',\n",
       " \"partner's\",\n",
       " 'phone.',\n",
       " \"'lock\",\n",
       " 'pf',\n",
       " 'blacksmith',\n",
       " 'demonstrate',\n",
       " 'previews.',\n",
       " 'improvement.',\n",
       " 'honesty',\n",
       " 'pine',\n",
       " 'histrionics',\n",
       " 'jayne',\n",
       " 'reasonable.',\n",
       " 'evening.',\n",
       " '108',\n",
       " 'asset.',\n",
       " 'controlled',\n",
       " 'clause',\n",
       " \"bard's\",\n",
       " 'substantive',\n",
       " 'framework.',\n",
       " 'pubic',\n",
       " 'infantry.',\n",
       " 'laundry.',\n",
       " 'lifestyles',\n",
       " 'narrow.',\n",
       " 'sewers',\n",
       " 'planned.',\n",
       " 'belle',\n",
       " 'classroom',\n",
       " 'mendes',\n",
       " 'tripped',\n",
       " 'strewn',\n",
       " 'doctor',\n",
       " 'jewish',\n",
       " 'recommends',\n",
       " 'fanboys',\n",
       " 'weakness.',\n",
       " 'sins',\n",
       " \"verhoeven's\",\n",
       " 'hooks',\n",
       " 'disparate',\n",
       " 'rochefort',\n",
       " 'ratty',\n",
       " 'stereotype.',\n",
       " 'ebay',\n",
       " 'author',\n",
       " 'uma',\n",
       " 'those',\n",
       " 'bianco',\n",
       " 'monsters.',\n",
       " 'louie',\n",
       " 'michele',\n",
       " 'into',\n",
       " 'sideline',\n",
       " 'superman',\n",
       " 'tormentor.',\n",
       " 'programs.',\n",
       " 'rationalize',\n",
       " 'wendigo',\n",
       " 'emotive',\n",
       " 'mastrosimone',\n",
       " 'mindset',\n",
       " 'evokes',\n",
       " 'beach',\n",
       " 'assembles',\n",
       " 'pressure',\n",
       " 'zeroes',\n",
       " 'prevailed.',\n",
       " 'payroll',\n",
       " 'hauntingly',\n",
       " 'meerkats',\n",
       " 'natasha',\n",
       " 'mistresses',\n",
       " 'completist',\n",
       " 'thirsty',\n",
       " 'ornament',\n",
       " 'qualities',\n",
       " 'fraction',\n",
       " 'blondes',\n",
       " 'performed.',\n",
       " 'adopts',\n",
       " 'acerbic',\n",
       " 'bolts.',\n",
       " 'firefly',\n",
       " 'bitterly',\n",
       " 'dalliance',\n",
       " 'stones',\n",
       " 'stay',\n",
       " 'signal',\n",
       " 'distress.',\n",
       " 'commander.',\n",
       " 'skills?',\n",
       " 'gab',\n",
       " 'nancy',\n",
       " 'snails',\n",
       " 'nypd',\n",
       " 'trio',\n",
       " 'unremarkable',\n",
       " 'lease',\n",
       " 'unsuccessful',\n",
       " 'oozing',\n",
       " 'akshay',\n",
       " 'primary',\n",
       " 'traumas',\n",
       " 'you.',\n",
       " 'pictured',\n",
       " 'sensationalism',\n",
       " 'filthy',\n",
       " 'babu',\n",
       " 'comically',\n",
       " 'leonardo',\n",
       " 'larceny',\n",
       " 'tsing',\n",
       " 'epps',\n",
       " 'volcanic',\n",
       " 'destroying',\n",
       " 'psychoanalysis',\n",
       " \"lead's\",\n",
       " 'viking',\n",
       " 'pilloried',\n",
       " \"thompson's\",\n",
       " 'gnomes',\n",
       " 'bucks!',\n",
       " 'soundtrack.',\n",
       " 'nope.',\n",
       " 'evolves',\n",
       " 'notre',\n",
       " 'wounder',\n",
       " 'stealing.',\n",
       " 'priceless',\n",
       " 'crystal.',\n",
       " 'zeta',\n",
       " 'consist',\n",
       " 'circles.',\n",
       " 'veronika',\n",
       " 'metallic',\n",
       " 'aarp',\n",
       " 'rafters',\n",
       " 'mulroney',\n",
       " 'dollar.',\n",
       " 'unmarried',\n",
       " 'mimicry.',\n",
       " 'display.',\n",
       " 'agape',\n",
       " 'pronouncement',\n",
       " 'definitive',\n",
       " 'adulteress',\n",
       " 'insufficient.',\n",
       " 'accused',\n",
       " 'brainwashing',\n",
       " 'desperado',\n",
       " '1944',\n",
       " 'scrambling',\n",
       " 'failures.',\n",
       " 'exxon',\n",
       " 'nerd',\n",
       " 'whatsoever...',\n",
       " 'alerted',\n",
       " 'bench',\n",
       " 'outstanding.',\n",
       " 'motorway',\n",
       " 'overlap',\n",
       " 'curley',\n",
       " 'hairstyles',\n",
       " 'worthwhile',\n",
       " 'pint',\n",
       " 'naseeruddin',\n",
       " 'kolchak',\n",
       " 'dope',\n",
       " 'truths.',\n",
       " 'directional',\n",
       " 'zelda',\n",
       " 'geiger',\n",
       " 'melies',\n",
       " 'molded',\n",
       " 'lorenzo',\n",
       " 'nudity',\n",
       " '4',\n",
       " 'st.',\n",
       " 'potente',\n",
       " 'hippie',\n",
       " 'slower',\n",
       " 'bankable',\n",
       " \"davidtz's\",\n",
       " 'inches',\n",
       " 'kiddies',\n",
       " 'birds.',\n",
       " 'convoy',\n",
       " 'bordered',\n",
       " 'johnny',\n",
       " 'bog',\n",
       " 'taxation',\n",
       " 'shopgirl',\n",
       " 'transcendence',\n",
       " 'vartan',\n",
       " 'sentiment.',\n",
       " 'perfectly',\n",
       " 'lillies',\n",
       " 'justice',\n",
       " 'fan?',\n",
       " 'penny.',\n",
       " 'meet',\n",
       " 'completely.',\n",
       " 'looked',\n",
       " 'georgia.',\n",
       " 'weirdest',\n",
       " 'idea?',\n",
       " 'hammered',\n",
       " 'tiring',\n",
       " \"duke's\",\n",
       " 'hawthorne',\n",
       " 'bolivia.',\n",
       " 'so?',\n",
       " 'fueling',\n",
       " 'accurate',\n",
       " \"your're\",\n",
       " 'oldest',\n",
       " 'exaggerating.',\n",
       " 'stunning.',\n",
       " 'limo',\n",
       " 'exited',\n",
       " 'caddie',\n",
       " 'propel',\n",
       " 'probation.',\n",
       " 'penniless',\n",
       " 'wired',\n",
       " \"e!'s\",\n",
       " 'alan.',\n",
       " 'disregard',\n",
       " 'ledger',\n",
       " 'mafia',\n",
       " 'grasped',\n",
       " 'contagious',\n",
       " 'nolte.',\n",
       " 'audie',\n",
       " \"who've\",\n",
       " 'trust.',\n",
       " 'outsourcing',\n",
       " 'bow',\n",
       " 'unpleasant.',\n",
       " 'munchausen',\n",
       " \"smith's\",\n",
       " 'shortages',\n",
       " 'experimented',\n",
       " 'lesley',\n",
       " 'sensibilities',\n",
       " 'procedures',\n",
       " 'skeptical.',\n",
       " '8.4',\n",
       " 'ace',\n",
       " 'patting',\n",
       " 'stuffs',\n",
       " 'sounded',\n",
       " 'paralysis',\n",
       " 'invader',\n",
       " 'self',\n",
       " \"cousin's\",\n",
       " 'disagreement',\n",
       " '1995.',\n",
       " 'preity',\n",
       " 'synthesis',\n",
       " \"hartley's\",\n",
       " 'koo',\n",
       " 'talented',\n",
       " 'britain',\n",
       " 'hostel',\n",
       " 'residence',\n",
       " 'oath',\n",
       " 'amiable',\n",
       " \"'one\",\n",
       " 'funny!',\n",
       " 'egg',\n",
       " 'ingenuous',\n",
       " 'mesh',\n",
       " 'profits',\n",
       " 'reactions.',\n",
       " 'screeching',\n",
       " 'dobie',\n",
       " 'clipping',\n",
       " 'proficiency',\n",
       " 'inventive.',\n",
       " 'proceedings',\n",
       " 'keir',\n",
       " 'resides',\n",
       " 'entirety.',\n",
       " 'admission',\n",
       " 'dw',\n",
       " 'wolf.',\n",
       " 'unquestionable',\n",
       " 'lacks',\n",
       " 'muni',\n",
       " 'incorrect',\n",
       " 'shanghai',\n",
       " 'everything...',\n",
       " 'decaying',\n",
       " 'drinking',\n",
       " 'cathy',\n",
       " 'cleaning',\n",
       " 'novice',\n",
       " 'enlivened',\n",
       " 'effecting',\n",
       " 'america!',\n",
       " 'feasible',\n",
       " '1982.',\n",
       " 'showed',\n",
       " 'drunkard',\n",
       " 'stripper',\n",
       " 'melodramatically',\n",
       " 'paradise',\n",
       " 'stately',\n",
       " 'vegas',\n",
       " 'whimsical',\n",
       " \"canada's\",\n",
       " 'merlin',\n",
       " 'eventual',\n",
       " 'proved.',\n",
       " 'insecurities.',\n",
       " 'conflict',\n",
       " 'parasite',\n",
       " 'stampede',\n",
       " 'deliveries',\n",
       " \"policeman's\",\n",
       " 'bullsh',\n",
       " 'funds',\n",
       " 'kyra',\n",
       " 'participation.',\n",
       " 'hoffmann',\n",
       " 'prosthetics',\n",
       " 'stagnated',\n",
       " 'teeny',\n",
       " 'constructed',\n",
       " 'much',\n",
       " 'dislike',\n",
       " 'comedy',\n",
       " 'kapadia',\n",
       " 'imbalance',\n",
       " 'carve',\n",
       " 'delude',\n",
       " 'h.b.',\n",
       " 'soothing',\n",
       " \"bbc's\",\n",
       " 'noel',\n",
       " 'superlative',\n",
       " 'separated',\n",
       " 'frog',\n",
       " 'classically',\n",
       " 'drama!',\n",
       " 'argentinian',\n",
       " 'unfilmable',\n",
       " 'sid',\n",
       " 'title!',\n",
       " 'solicited',\n",
       " 'bad?',\n",
       " 'fool',\n",
       " 'deliriously',\n",
       " 'quaint',\n",
       " 'reflex',\n",
       " 'contradicting',\n",
       " 'spaniard.',\n",
       " 'witchcraft',\n",
       " 'ice',\n",
       " 'quitting',\n",
       " 'yelling.',\n",
       " 'sympathise',\n",
       " 'look',\n",
       " 'regretfully',\n",
       " 'exemplary',\n",
       " '48',\n",
       " 'b.c.',\n",
       " 'doubtful',\n",
       " 'iñárritu',\n",
       " 'leering',\n",
       " 'minutely',\n",
       " \"black's\",\n",
       " 'hokum',\n",
       " 'petit',\n",
       " 'bowel',\n",
       " 'grabs',\n",
       " 'producer',\n",
       " 'ordinarily',\n",
       " 'intensifies',\n",
       " 'tackles',\n",
       " 'correctly',\n",
       " 'bootleg',\n",
       " 'château.',\n",
       " \"'less\",\n",
       " '1973.',\n",
       " 'estelle',\n",
       " 'actors?',\n",
       " 'smitrovich',\n",
       " 'returns',\n",
       " '94',\n",
       " \"'straight'\",\n",
       " 'cassinelli',\n",
       " 'jeopardy',\n",
       " 'pet',\n",
       " 'cranking',\n",
       " 'whacky',\n",
       " 'leave',\n",
       " 'leung',\n",
       " 'prestigious',\n",
       " 'dirt',\n",
       " 'wincott',\n",
       " 'spotless',\n",
       " 'lovely',\n",
       " 'contestants',\n",
       " 'unseemly',\n",
       " 'boyfriends.',\n",
       " 'guest',\n",
       " \"down's\",\n",
       " \"union's\",\n",
       " 'overheard',\n",
       " 'redundancy',\n",
       " 'crudeness',\n",
       " 'recording.',\n",
       " 'complex',\n",
       " 'bleach',\n",
       " 'finely',\n",
       " 'pakistan',\n",
       " 'stella',\n",
       " 'jan',\n",
       " 'sheen',\n",
       " 'existed',\n",
       " 'gods.',\n",
       " 'screwing',\n",
       " 'cried.',\n",
       " 'dose',\n",
       " 'worlds',\n",
       " 'drunken',\n",
       " 'yankovic',\n",
       " 'offered',\n",
       " 'chou.',\n",
       " 'dashes',\n",
       " 'immediately.',\n",
       " 'cynic',\n",
       " 'comparatively',\n",
       " 'multiple',\n",
       " 'require',\n",
       " 'pouting',\n",
       " 'engulfed',\n",
       " 'whatsoever!',\n",
       " 'played.',\n",
       " 'mired',\n",
       " 'forgot',\n",
       " 'instalment',\n",
       " 'ice.',\n",
       " 'construct',\n",
       " 'winners',\n",
       " \"streisand's\",\n",
       " 'benefits',\n",
       " 'apropos',\n",
       " 'corporation',\n",
       " 'retrospect',\n",
       " 'acknowledge',\n",
       " 'grizzly',\n",
       " 'peep',\n",
       " 'anime.',\n",
       " 'classify',\n",
       " 'blows.',\n",
       " 'faults.',\n",
       " 'just',\n",
       " 'dearest',\n",
       " 'turbulence',\n",
       " 'food.',\n",
       " 'released?',\n",
       " 'soften',\n",
       " 'quarters',\n",
       " 'addict.',\n",
       " 'institute.',\n",
       " 'switchblade',\n",
       " 'trouble.',\n",
       " 'collar.',\n",
       " 'cocteau',\n",
       " 'constructed.',\n",
       " 'jacky',\n",
       " 'infancy',\n",
       " 'hits',\n",
       " 'adds.',\n",
       " 'trading',\n",
       " 'lying.',\n",
       " 'toto',\n",
       " 'fine!',\n",
       " 'aircraft',\n",
       " 'purple.',\n",
       " 'cramer',\n",
       " 'familiar',\n",
       " 'blacked',\n",
       " 'anu',\n",
       " 'viewpoint.',\n",
       " 'recessive',\n",
       " 'liked',\n",
       " 'studio',\n",
       " 'females',\n",
       " 'vanished.',\n",
       " 'jiménez',\n",
       " 'moon?',\n",
       " 'flips',\n",
       " 'davison',\n",
       " 'crops',\n",
       " 'bombshell',\n",
       " 'erstwhile',\n",
       " 'jilted',\n",
       " 'beverly',\n",
       " 'confides',\n",
       " 'confrontational',\n",
       " 'dermot',\n",
       " 'pithy',\n",
       " 'napier',\n",
       " 'uncharacteristic',\n",
       " 'colombo.',\n",
       " 'coz',\n",
       " 'abandoned',\n",
       " 'cancellation',\n",
       " 'pianist',\n",
       " 'chemist',\n",
       " 'poof',\n",
       " \"'special\",\n",
       " \"devil'\",\n",
       " 'bogdanovich',\n",
       " 'branches',\n",
       " 'y.',\n",
       " 'eyre',\n",
       " 'r',\n",
       " 'attempted',\n",
       " 'mejding',\n",
       " 'hungary',\n",
       " 'genocide',\n",
       " 'assuming',\n",
       " 'plantation',\n",
       " 'male.',\n",
       " 'expects',\n",
       " 'wickedness',\n",
       " 'enjoyably',\n",
       " 'wrote.',\n",
       " \"guru's\",\n",
       " 'system',\n",
       " 'beaches.',\n",
       " 'elisabeth',\n",
       " 'wash.',\n",
       " 'fellini',\n",
       " 'passionate',\n",
       " 'scarlet',\n",
       " 'baffle',\n",
       " 'homer',\n",
       " 'interested?',\n",
       " 'hysterical!',\n",
       " 'writing!',\n",
       " '14th',\n",
       " 'thirties.',\n",
       " 'galindo',\n",
       " 'body.',\n",
       " 'militant',\n",
       " 'fries',\n",
       " 'darkly',\n",
       " 'existence',\n",
       " 'overenthusiastic',\n",
       " 'apprehended',\n",
       " 'future?',\n",
       " 'preston.',\n",
       " 'hooligans',\n",
       " 'concert',\n",
       " 'timely',\n",
       " '1952',\n",
       " 'silvio',\n",
       " 'picturised',\n",
       " 'indescribably',\n",
       " 'chart',\n",
       " 'calamity',\n",
       " 'firefighters',\n",
       " \"me'\",\n",
       " 'performance?',\n",
       " 'homemade',\n",
       " 'hops',\n",
       " 'reserve',\n",
       " 'dispense',\n",
       " 'figuring',\n",
       " 'dalai',\n",
       " 'repetition.',\n",
       " 'complaining',\n",
       " 'ceasar',\n",
       " 'seventh',\n",
       " 'earlier.',\n",
       " 'nicholas',\n",
       " 'work',\n",
       " 'returning',\n",
       " 'zombi.',\n",
       " 'phoned',\n",
       " 'urinating',\n",
       " 'everyman.',\n",
       " \"o'hearn\",\n",
       " 'unexplained.',\n",
       " 'dragon.',\n",
       " 'poignant.',\n",
       " 'universities',\n",
       " 'morphs',\n",
       " 'mitzi',\n",
       " 'peter.',\n",
       " 'delicate',\n",
       " 'slyly',\n",
       " 'electronic',\n",
       " 'outstandingly',\n",
       " 'shrill',\n",
       " 'zappa',\n",
       " 'interview',\n",
       " 'reading',\n",
       " 'listings',\n",
       " 'intended.',\n",
       " 'plumber',\n",
       " 'enthusiasm.',\n",
       " 'clashing',\n",
       " \"yesterday's\",\n",
       " 'eaters',\n",
       " 'choices.',\n",
       " 'johnny!',\n",
       " 'women...',\n",
       " 'cliffhanger.',\n",
       " 'mutters',\n",
       " 'asylum',\n",
       " 'fun...',\n",
       " 'great!',\n",
       " 'fisher',\n",
       " 'alleys',\n",
       " 'dratch',\n",
       " 'song',\n",
       " 'nerves',\n",
       " 'max',\n",
       " 'kinds',\n",
       " 'authentic',\n",
       " 'affinity',\n",
       " 'catastrophic.',\n",
       " 'yada',\n",
       " 'jeanie',\n",
       " 'empower',\n",
       " 'foo',\n",
       " 'anime?',\n",
       " 'dippy',\n",
       " 'undies',\n",
       " 'dario',\n",
       " 'tending',\n",
       " 'designed.',\n",
       " 'built.',\n",
       " 'respectfully',\n",
       " 'blown',\n",
       " 'youth.',\n",
       " 'moves',\n",
       " 'ioan',\n",
       " 'titanic',\n",
       " 'cemented',\n",
       " 'workplace',\n",
       " 'evacuees',\n",
       " 'cloud',\n",
       " 'platform',\n",
       " 'worse',\n",
       " 'nesbitt',\n",
       " 'everyday.',\n",
       " 'albans',\n",
       " '1936',\n",
       " 'project',\n",
       " 'wu',\n",
       " 'hazy',\n",
       " 'adventurous',\n",
       " 'snag',\n",
       " 'savagery',\n",
       " 'medals',\n",
       " 'garfield',\n",
       " 'directions.',\n",
       " 'lezlie',\n",
       " 'gavras',\n",
       " 'punishment.',\n",
       " 'uselessness',\n",
       " 'ageless',\n",
       " 'cowboy',\n",
       " 'juarez',\n",
       " 'wincing',\n",
       " 'billy',\n",
       " 'analogy',\n",
       " 'reporter.',\n",
       " 'bungalow',\n",
       " \"'well\",\n",
       " 'smarts',\n",
       " \"'child'\",\n",
       " 'died?',\n",
       " 'adventurers',\n",
       " 'critic.',\n",
       " 'frustrate',\n",
       " 'tony',\n",
       " 'walker',\n",
       " 'coincide',\n",
       " 'potential',\n",
       " 'twice',\n",
       " 'bray',\n",
       " 'brutalized',\n",
       " 'pairings',\n",
       " 'mishandled',\n",
       " 'rugrats',\n",
       " 'ending',\n",
       " 'additionally',\n",
       " 'what',\n",
       " 'scumbags',\n",
       " 'god',\n",
       " 'bespectacled',\n",
       " 'disenchanted',\n",
       " 'undo',\n",
       " 'rash',\n",
       " 'move.',\n",
       " 'whiner.',\n",
       " 'one...and',\n",
       " 'suggestion.',\n",
       " 'aunts.',\n",
       " 'harassing',\n",
       " 'fireworks!',\n",
       " 'body',\n",
       " 'dapper',\n",
       " \"jackson's\",\n",
       " 'harder.',\n",
       " 'rhymes',\n",
       " 'beleaguered',\n",
       " 'syndrome.',\n",
       " 'stilted.',\n",
       " \"bacall's\",\n",
       " 'helped',\n",
       " 'bachchan',\n",
       " 'concepts.',\n",
       " 'solo',\n",
       " 'tgif',\n",
       " 'skids',\n",
       " 'homosexual.',\n",
       " 'doodlebops',\n",
       " 'unarmed',\n",
       " 'dawson',\n",
       " 'film...but',\n",
       " 'snuck',\n",
       " 'spoilers?',\n",
       " 'join',\n",
       " 'hitman',\n",
       " 'mayhem',\n",
       " 'minded',\n",
       " 'nostalgic...',\n",
       " 'oddness',\n",
       " 'local',\n",
       " '110',\n",
       " 'medley',\n",
       " 'characatures',\n",
       " 'grammar.',\n",
       " 'fully',\n",
       " '!',\n",
       " 'blanks',\n",
       " 'jerker',\n",
       " 'cabinet',\n",
       " 'arrested',\n",
       " 'cursing',\n",
       " 'satire',\n",
       " 'functional.',\n",
       " 'sewer.',\n",
       " 'unraveled.',\n",
       " 'applied',\n",
       " 'luis',\n",
       " 'intervals',\n",
       " 'hallway.',\n",
       " 'wedged',\n",
       " 'monotony',\n",
       " 'transforming',\n",
       " 'packs',\n",
       " 'schtick',\n",
       " 'of!',\n",
       " 'sympathy.',\n",
       " 'piloted',\n",
       " 'apprehend',\n",
       " 'koji',\n",
       " 'confines',\n",
       " 'lighthouse',\n",
       " 'unforgettable',\n",
       " \"page's\",\n",
       " 'cretins',\n",
       " 'casually',\n",
       " 'goldeneye',\n",
       " 'mate!',\n",
       " '4.3',\n",
       " 'oldie',\n",
       " 'bored.',\n",
       " 'intriguing.',\n",
       " \"her's\",\n",
       " 'canon',\n",
       " 'monetary',\n",
       " 'baghdad',\n",
       " 'that.the',\n",
       " 'tragically',\n",
       " 'kirkland',\n",
       " 'danish',\n",
       " 'quiet',\n",
       " 'smooth',\n",
       " 'atlantian',\n",
       " 'detonator',\n",
       " 'ours.',\n",
       " 'at',\n",
       " 'comfort',\n",
       " 'kitsch',\n",
       " 'airtight',\n",
       " 'liberties',\n",
       " 'chairman',\n",
       " 'bookended',\n",
       " 'lyle',\n",
       " 'accorded',\n",
       " 'holed',\n",
       " 'kwai',\n",
       " 'tivo',\n",
       " 'dormant',\n",
       " 'hollywoodian',\n",
       " 'pass',\n",
       " 'yesterday',\n",
       " 'hines',\n",
       " 'opus.',\n",
       " 'biting',\n",
       " 'infighting',\n",
       " 'overnight',\n",
       " 'affections',\n",
       " 'sos',\n",
       " 'grieco',\n",
       " 'consumerist',\n",
       " 'videotaped',\n",
       " 'perverts',\n",
       " 'sojourn',\n",
       " 'skulking',\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter.keys() & neg_counter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995ce69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72d2c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "common_words = pos_counter.keys() | neg_counter.keys()\n",
    "\n",
    "pos_n = sum(pos_counter.values())\n",
    "neg_n = sum(neg_counter.values())\n",
    "\n",
    "word_to_nb_weight = dict()\n",
    "\n",
    "for word in common_words:\n",
    "    p_w_pos = pos_counter[word] / pos_n\n",
    "    p_w_neg = neg_counter[word] / neg_n\n",
    "    \n",
    "    #print(word)\n",
    "    nb_weight = math.log((p_w_pos + 1e-7) / (p_w_neg + 1e-7) )\n",
    "    word_to_nb_weight[word] = nb_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f31ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_counter.keys() - neg_counter.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a096988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [(word, nb_weight, pos_counter[word], neg_counter[word]) for word, nb_weight in word_to_nb_weight.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5713ba15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thunderbirds', -5.3178282602560705, 0, 36),\n",
       " ('beowulf', -5.136486901123298, 0, 30),\n",
       " ('atrocious.', -5.1027880290634835, 0, 29),\n",
       " ('unwatchable.', -5.1027880290634835, 0, 29),\n",
       " ('ajay', -5.1027880290634835, 0, 29),\n",
       " ('deathstalker', -5.031779317208724, 0, 27),\n",
       " ('dahmer', -4.994290003346008, 0, 26),\n",
       " ('kareena', -4.955340314690489, 0, 25),\n",
       " ('welch', -4.914811847175403, 0, 24),\n",
       " ('thinking?', -4.914811847175403, 0, 24),\n",
       " ('turgid', -4.914811847175403, 0, 24),\n",
       " ('ripley', -4.872571186157663, 0, 23),\n",
       " ('sarne', -4.872571186157663, 0, 23),\n",
       " ('grendel', -4.872571186157663, 0, 23),\n",
       " ('stinker.', -4.872571186157663, 0, 23),\n",
       " ('varma', -4.782328062512033, 0, 21),\n",
       " ('palermo', -4.782328062512033, 0, 21),\n",
       " ('slater', -4.782328062512033, 0, 21),\n",
       " ('kinski', -4.782328062512033, 0, 21),\n",
       " ('kibbutz', -4.733956634425011, 0, 20),\n",
       " ('flop.', -4.733956634425011, 0, 20),\n",
       " ('maddy', -4.733956634425011, 0, 20),\n",
       " ('steaming', -4.6831259496970326, 0, 19),\n",
       " ('orca', -4.6831259496970326, 0, 19),\n",
       " ('dreck.', -4.6831259496970326, 0, 19),\n",
       " ('start?', -4.6831259496970326, 0, 19),\n",
       " ('hobgoblins', -4.62957248828758, 0, 18),\n",
       " ('manos', -4.62957248828758, 0, 18),\n",
       " ('bigelow', -4.62957248828758, 0, 18),\n",
       " ('hackenstein', -4.62957248828758, 0, 18)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(weights, key=lambda x: x[1])[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a53594fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 5.992289209086858, 73, 0),\n",
       " ('antwone', 5.936081070121319, 69, 0),\n",
       " ('gundam', 5.813194909289788, 61, 0),\n",
       " ('paulie', 5.745581965978395, 57, 0),\n",
       " ('mildred', 5.634732362928491, 51, 0),\n",
       " ('corbett', 5.392767901353049, 40, 0),\n",
       " ('flavia', 5.367566736916988, 39, 0),\n",
       " ('deathtrap', 5.259886206729456, 35, 0),\n",
       " ('biko', 5.170761044682313, 32, 0),\n",
       " ('trier', 5.139195563268109, 31, 0),\n",
       " ('ossessione', 5.106601134812726, 30, 0),\n",
       " ('din', 5.106601134812726, 30, 0),\n",
       " ('yokai', 5.106601134812726, 30, 0),\n",
       " ('gunga', 5.072908410767607, 29, 0),\n",
       " ('creasy', 5.038040786464192, 28, 0),\n",
       " ('daisies', 5.001913352114944, 27, 0),\n",
       " ('mclaglen', 5.001913352114944, 27, 0),\n",
       " ('treat.', 5.001913352114944, 27, 0),\n",
       " ('brashear', 4.964431647119351, 26, 0),\n",
       " ('gino', 4.964431647119351, 26, 0),\n",
       " ('visconti', 4.964431647119351, 26, 0),\n",
       " ('tsui', 4.964431647119351, 26, 0),\n",
       " ('ultimatum', 4.925490171686578, 25, 0),\n",
       " ('offside', 4.88497059673164, 24, 0),\n",
       " (\"victoria's\", 4.88497059673164, 24, 0),\n",
       " ('rea', 4.88497059673164, 24, 0),\n",
       " ('fineman', 4.88497059673164, 24, 0),\n",
       " ('melbourne', 4.88497059673164, 24, 0),\n",
       " ('blandings', 4.88497059673164, 24, 0),\n",
       " ('enjoy!', 4.842739595532225, 23, 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(weights, key=lambda x: x[1])[::-1][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f5655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ec2d94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Naive Bayes Weight</th>\n",
       "      <th>Count Positive</th>\n",
       "      <th>Count Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thunderbirds</td>\n",
       "      <td>-5.317828</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beowulf</td>\n",
       "      <td>-5.136487</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atrocious.</td>\n",
       "      <td>-5.102788</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unwatchable.</td>\n",
       "      <td>-5.102788</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ajay</td>\n",
       "      <td>-5.102788</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Naive Bayes Weight  Count Positive  Count Negative\n",
       "0  thunderbirds           -5.317828               0              36\n",
       "1       beowulf           -5.136487               0              30\n",
       "2    atrocious.           -5.102788               0              29\n",
       "3  unwatchable.           -5.102788               0              29\n",
       "4          ajay           -5.102788               0              29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = pd.DataFrame(sorted(weights, key=lambda x: x[1])[:30], columns=['Word', 'Naive Bayes Weight', 'Count Positive', 'Count Negative'])\n",
    "min_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67c40c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36b74e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(min_df.style, 'min30.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04df015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Naive Bayes Weight</th>\n",
       "      <th>Count Positive</th>\n",
       "      <th>Count Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edie</td>\n",
       "      <td>5.992289</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antwone</td>\n",
       "      <td>5.936081</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gundam</td>\n",
       "      <td>5.813195</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paulie</td>\n",
       "      <td>5.745582</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mildred</td>\n",
       "      <td>5.634732</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Naive Bayes Weight  Count Positive  Count Negative\n",
       "0     edie            5.992289              73               0\n",
       "1  antwone            5.936081              69               0\n",
       "2   gundam            5.813195              61               0\n",
       "3   paulie            5.745582              57               0\n",
       "4  mildred            5.634732              51               0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_df = pd.DataFrame(sorted(weights, key=lambda x: x[1])[::-1][:30], columns=['Word', 'Naive Bayes Weight', 'Count Positive', 'Count Negative'])\n",
    "max_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4c64f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(max_df.style, 'max30.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6df19fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Predicting on test time</th>\n",
       "      <th>train acc</th>\n",
       "      <th>dev acc</th>\n",
       "      <th>dev-b acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>3.58s</td>\n",
       "      <td>798.84s</td>\n",
       "      <td>95.10</td>\n",
       "      <td>85.64</td>\n",
       "      <td>73.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNB</td>\n",
       "      <td>2.35s</td>\n",
       "      <td>938.03s</td>\n",
       "      <td>93.17</td>\n",
       "      <td>84.63</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Training time Predicting on test time  train acc  dev acc  dev-b acc\n",
       "0    NB         3.58s                 798.84s      95.10    85.64      73.75\n",
       "1   MNB         2.35s                 938.03s      93.17    84.63      73.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_row = {'Model': 'NB', 'Training time': '3.58s', 'Predicting on test time': '798.84s', 'train acc': 95.10, 'dev acc': 85.64, 'dev-b acc': 73.75}\n",
    "mnb_row = {'Model': 'MNB', 'Training time': '2.35s', 'Predicting on test time': '938.03s', 'train acc': 93.17, 'dev acc': 84.63, 'dev-b acc': 73.00}\n",
    "\n",
    "pd.DataFrame([nb_row, mnb_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22792136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db262ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0933e968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thunderbirds', -5.3178282602560705),\n",
       " ('beowulf', -5.136486901123298),\n",
       " ('ajay', -5.1027880290634835),\n",
       " ('atrocious.', -5.1027880290634835),\n",
       " ('unwatchable.', -5.1027880290634835),\n",
       " ('deathstalker', -5.031779317208724),\n",
       " ('dahmer', -4.994290003346008),\n",
       " ('kareena', -4.955340314690489),\n",
       " ('turgid', -4.914811847175403),\n",
       " ('welch', -4.914811847175403),\n",
       " ('thinking?', -4.914811847175403),\n",
       " ('sarne', -4.872571186157663),\n",
       " ('stinker.', -4.872571186157663),\n",
       " ('grendel', -4.872571186157663),\n",
       " ('ripley', -4.872571186157663),\n",
       " ('slater', -4.782328062512033),\n",
       " ('varma', -4.782328062512033),\n",
       " ('kinski', -4.782328062512033),\n",
       " ('palermo', -4.782328062512033),\n",
       " ('flop.', -4.733956634425011),\n",
       " ('kibbutz', -4.733956634425011),\n",
       " ('maddy', -4.733956634425011),\n",
       " ('dreck.', -4.6831259496970326),\n",
       " ('orca', -4.6831259496970326),\n",
       " ('steaming', -4.6831259496970326),\n",
       " ('start?', -4.6831259496970326),\n",
       " ('hackenstein', -4.62957248828758),\n",
       " ('manos', -4.62957248828758),\n",
       " ('hobgoblins', -4.62957248828758),\n",
       " ('voodoo', -4.62957248828758)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_to_nb_weight.items(), key=lambda x: x[1])[:30]   #, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6d572c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alvin', 3.037987769146273),\n",
       " ('lin', 3.0609772873709717),\n",
       " ('dev', 3.0609772873709717),\n",
       " (\"sinatra's\", 3.0609772873709717),\n",
       " ('sho', 3.0609772873709717),\n",
       " (\"chan's\", 3.1054290499418054),\n",
       " ('lindy', 3.1054290499418054),\n",
       " ('luzhin', 3.1479886643606014),\n",
       " ('cheung', 3.1479886643606014),\n",
       " ('polanski', 3.168607951563337),\n",
       " ('giovanna', 3.1888106588808562),\n",
       " ('vertigo', 3.1888106588808562),\n",
       " ('haines', 3.1888106588808562),\n",
       " ('stardust', 3.228031372034138),\n",
       " ('evans', 3.228031372034138),\n",
       " ('bourne', 3.228031372034138),\n",
       " ('anchors', 3.265771700016985),\n",
       " ('delightfully', 3.3021393441878595),\n",
       " ('anton', 3.33723066399913),\n",
       " ('chavez', 3.371132215674811),\n",
       " (\"kelly's\", 3.371132215674811),\n",
       " ('philo', 3.403922038497802),\n",
       " ('clara', 3.403922038497802),\n",
       " ('pixar', 3.435670736812382),\n",
       " (\"tony's\", 3.435670736812382),\n",
       " ('excellently', 3.435670736812382),\n",
       " ('mathieu', 3.633496480142302),\n",
       " ('adele', 3.633496480142302),\n",
       " ('kolchak', 3.6835069007169636),\n",
       " ('sox', 3.95891888057693)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_to_nb_weight.items(), key=lambda x: x[1])[-30:]   #, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54565f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 39)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counter[\"god's\"], neg_counter[\"god's\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8274a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798fabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e214e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a550ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69d2bd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb5369fee3e4487b35d0cdf22105493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text, label in notebook.tqdm(pos):\n",
    "    tokenized_text = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffb51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9d717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f43e1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "except_list = \".?!\"\n",
    "p = re.compile(fr\"[^\\w'+{except_list}+']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17c20b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "954593fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought Rachel York was fantastic as \"Lucy.\" I have seen her in \"Kiss Me, Kate\" and \"Victor/Victoria,\" as well, and in each of these performances she has developed very different, and very real, characterizations. She is a chameleon who can play (and sing) anything!<br /><br />I am very surprised at how many negative reviews appear here regarding Rachel\\'s performance in \"Lucy.\" Even some bonafide TV and entertainment critics seem to have missed the point of her portrayal. So many people have focused on the fact that Rachel doesn\\'t really look like Lucy. My response to that is, \"So what?\" I wasn\\'t looking for a superficial impersonation of Lucy. I wanted to know more about the real woman behind the clown. And Rachel certainly gave us that, in great depth. I also didn\\'t want to see someone simply \"doing\" classic Lucy routines. Therefore I was very pleased with the decision by the producers and director to have Rachel portray Lucy in rehearsal for the most memorable of these skits - Vitameatavegamin and The Candy Factory. (It seems that some of the reviewers didn\\'t realize that these two scenes were meant to be rehearsal sequences and not the actual skits). This approach, I thought, gave an innovative twist to sketches that so many of us know by heart. I also thought Rachel was terrifically fresh and funny in these scenes. And she absolutely nailed the routines that were recreated - the Professor and the Grape Stomping, in particular. There was one moment in the Grape scene where the corner of Rachel\\'s mouth had the exact little upturn that I remember Lucy having. I couldn\\'t believe she was able to capture that - and so naturally.<br /><br />I wonder if many of the folks who criticized the performance were expecting to see the Lucille Ball of \"I Love Lucy\" throughout the entire movie. After all, those of us who came to know her only through TV would not have any idea what Lucy was really like in her early movie years. I think Rachel showed a natural progression in the character that was brilliant. She planted all the right seeds for us to see the clown just waiting to emerge, given the right set of circumstances. Lucy didn\\'t fit the mold of the old studio system. In her frustrated attempts to become the stereotypical movie star of that era, she kept repressing what would prove to be her ultimate gifts.<br /><br />I believe that Rachel deftly captured the comedy, drama, wit, sadness, anger, passion, love, ambition, loyalty, sexiness, self absorption, childishness, and stoicism all rolled into one complex American icon. And she did it with an authenticity and freshness that was totally endearing. \"Lucy\" was a star turn for Rachel York. I hope it brings a flood of great roles her way in the future. I also hope it brings her an Emmy.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[101][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b03311e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'thought',\n",
       " 'rachel',\n",
       " 'york',\n",
       " 'was',\n",
       " 'fantastic',\n",
       " 'as',\n",
       " 'lucy.',\n",
       " 'i',\n",
       " 'have',\n",
       " 'seen',\n",
       " 'her',\n",
       " 'in',\n",
       " 'kiss',\n",
       " 'me',\n",
       " 'kate',\n",
       " 'and',\n",
       " 'victor',\n",
       " 'victoria',\n",
       " 'as',\n",
       " 'well',\n",
       " 'and',\n",
       " 'in',\n",
       " 'each',\n",
       " 'of',\n",
       " 'these',\n",
       " 'performances',\n",
       " 'she',\n",
       " 'has',\n",
       " 'developed',\n",
       " 'very',\n",
       " 'different',\n",
       " 'and',\n",
       " 'very',\n",
       " 'real',\n",
       " 'characterizations.',\n",
       " 'she',\n",
       " 'is',\n",
       " 'a',\n",
       " 'chameleon',\n",
       " 'who',\n",
       " 'can',\n",
       " 'play',\n",
       " 'and',\n",
       " 'sing',\n",
       " 'anything!',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " 'am',\n",
       " 'very',\n",
       " 'surprised',\n",
       " 'at',\n",
       " 'how',\n",
       " 'many',\n",
       " 'negative',\n",
       " 'reviews',\n",
       " 'appear',\n",
       " 'here',\n",
       " 'regarding',\n",
       " \"rachel's\",\n",
       " 'performance',\n",
       " 'in',\n",
       " 'lucy.',\n",
       " 'even',\n",
       " 'some',\n",
       " 'bonafide',\n",
       " 'tv',\n",
       " 'and',\n",
       " 'entertainment',\n",
       " 'critics',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'have',\n",
       " 'missed',\n",
       " 'the',\n",
       " 'point',\n",
       " 'of',\n",
       " 'her',\n",
       " 'portrayal.',\n",
       " 'so',\n",
       " 'many',\n",
       " 'people',\n",
       " 'have',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'rachel',\n",
       " \"doesn't\",\n",
       " 'really',\n",
       " 'look',\n",
       " 'like',\n",
       " 'lucy.',\n",
       " 'my',\n",
       " 'response',\n",
       " 'to',\n",
       " 'that',\n",
       " 'is',\n",
       " 'so',\n",
       " 'what?',\n",
       " 'i',\n",
       " \"wasn't\",\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'superficial',\n",
       " 'impersonation',\n",
       " 'of',\n",
       " 'lucy.',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'know',\n",
       " 'more',\n",
       " 'about',\n",
       " 'the',\n",
       " 'real',\n",
       " 'woman',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'clown.',\n",
       " 'and',\n",
       " 'rachel',\n",
       " 'certainly',\n",
       " 'gave',\n",
       " 'us',\n",
       " 'that',\n",
       " 'in',\n",
       " 'great',\n",
       " 'depth.',\n",
       " 'i',\n",
       " 'also',\n",
       " \"didn't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'someone',\n",
       " 'simply',\n",
       " 'doing',\n",
       " 'classic',\n",
       " 'lucy',\n",
       " 'routines.',\n",
       " 'therefore',\n",
       " 'i',\n",
       " 'was',\n",
       " 'very',\n",
       " 'pleased',\n",
       " 'with',\n",
       " 'the',\n",
       " 'decision',\n",
       " 'by',\n",
       " 'the',\n",
       " 'producers',\n",
       " 'and',\n",
       " 'director',\n",
       " 'to',\n",
       " 'have',\n",
       " 'rachel',\n",
       " 'portray',\n",
       " 'lucy',\n",
       " 'in',\n",
       " 'rehearsal',\n",
       " 'for',\n",
       " 'the',\n",
       " 'most',\n",
       " 'memorable',\n",
       " 'of',\n",
       " 'these',\n",
       " 'skits',\n",
       " 'vitameatavegamin',\n",
       " 'and',\n",
       " 'the',\n",
       " 'candy',\n",
       " 'factory.',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reviewers',\n",
       " \"didn't\",\n",
       " 'realize',\n",
       " 'that',\n",
       " 'these',\n",
       " 'two',\n",
       " 'scenes',\n",
       " 'were',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'be',\n",
       " 'rehearsal',\n",
       " 'sequences',\n",
       " 'and',\n",
       " 'not',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'skits',\n",
       " '.',\n",
       " 'this',\n",
       " 'approach',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'gave',\n",
       " 'an',\n",
       " 'innovative',\n",
       " 'twist',\n",
       " 'to',\n",
       " 'sketches',\n",
       " 'that',\n",
       " 'so',\n",
       " 'many',\n",
       " 'of',\n",
       " 'us',\n",
       " 'know',\n",
       " 'by',\n",
       " 'heart.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'thought',\n",
       " 'rachel',\n",
       " 'was',\n",
       " 'terrifically',\n",
       " 'fresh',\n",
       " 'and',\n",
       " 'funny',\n",
       " 'in',\n",
       " 'these',\n",
       " 'scenes.',\n",
       " 'and',\n",
       " 'she',\n",
       " 'absolutely',\n",
       " 'nailed',\n",
       " 'the',\n",
       " 'routines',\n",
       " 'that',\n",
       " 'were',\n",
       " 'recreated',\n",
       " 'the',\n",
       " 'professor',\n",
       " 'and',\n",
       " 'the',\n",
       " 'grape',\n",
       " 'stomping',\n",
       " 'in',\n",
       " 'particular.',\n",
       " 'there',\n",
       " 'was',\n",
       " 'one',\n",
       " 'moment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grape',\n",
       " 'scene',\n",
       " 'where',\n",
       " 'the',\n",
       " 'corner',\n",
       " 'of',\n",
       " \"rachel's\",\n",
       " 'mouth',\n",
       " 'had',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'little',\n",
       " 'upturn',\n",
       " 'that',\n",
       " 'i',\n",
       " 'remember',\n",
       " 'lucy',\n",
       " 'having.',\n",
       " 'i',\n",
       " \"couldn't\",\n",
       " 'believe',\n",
       " 'she',\n",
       " 'was',\n",
       " 'able',\n",
       " 'to',\n",
       " 'capture',\n",
       " 'that',\n",
       " 'and',\n",
       " 'so',\n",
       " 'naturally.',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'if',\n",
       " 'many',\n",
       " 'of',\n",
       " 'the',\n",
       " 'folks',\n",
       " 'who',\n",
       " 'criticized',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'were',\n",
       " 'expecting',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'lucille',\n",
       " 'ball',\n",
       " 'of',\n",
       " 'i',\n",
       " 'love',\n",
       " 'lucy',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'movie.',\n",
       " 'after',\n",
       " 'all',\n",
       " 'those',\n",
       " 'of',\n",
       " 'us',\n",
       " 'who',\n",
       " 'came',\n",
       " 'to',\n",
       " 'know',\n",
       " 'her',\n",
       " 'only',\n",
       " 'through',\n",
       " 'tv',\n",
       " 'would',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'idea',\n",
       " 'what',\n",
       " 'lucy',\n",
       " 'was',\n",
       " 'really',\n",
       " 'like',\n",
       " 'in',\n",
       " 'her',\n",
       " 'early',\n",
       " 'movie',\n",
       " 'years.',\n",
       " 'i',\n",
       " 'think',\n",
       " 'rachel',\n",
       " 'showed',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'progression',\n",
       " 'in',\n",
       " 'the',\n",
       " 'character',\n",
       " 'that',\n",
       " 'was',\n",
       " 'brilliant.',\n",
       " 'she',\n",
       " 'planted',\n",
       " 'all',\n",
       " 'the',\n",
       " 'right',\n",
       " 'seeds',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'clown',\n",
       " 'just',\n",
       " 'waiting',\n",
       " 'to',\n",
       " 'emerge',\n",
       " 'given',\n",
       " 'the',\n",
       " 'right',\n",
       " 'set',\n",
       " 'of',\n",
       " 'circumstances.',\n",
       " 'lucy',\n",
       " \"didn't\",\n",
       " 'fit',\n",
       " 'the',\n",
       " 'mold',\n",
       " 'of',\n",
       " 'the',\n",
       " 'old',\n",
       " 'studio',\n",
       " 'system.',\n",
       " 'in',\n",
       " 'her',\n",
       " 'frustrated',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'become',\n",
       " 'the',\n",
       " 'stereotypical',\n",
       " 'movie',\n",
       " 'star',\n",
       " 'of',\n",
       " 'that',\n",
       " 'era',\n",
       " 'she',\n",
       " 'kept',\n",
       " 'repressing',\n",
       " 'what',\n",
       " 'would',\n",
       " 'prove',\n",
       " 'to',\n",
       " 'be',\n",
       " 'her',\n",
       " 'ultimate',\n",
       " 'gifts.',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'rachel',\n",
       " 'deftly',\n",
       " 'captured',\n",
       " 'the',\n",
       " 'comedy',\n",
       " 'drama',\n",
       " 'wit',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'passion',\n",
       " 'love',\n",
       " 'ambition',\n",
       " 'loyalty',\n",
       " 'sexiness',\n",
       " 'self',\n",
       " 'absorption',\n",
       " 'childishness',\n",
       " 'and',\n",
       " 'stoicism',\n",
       " 'all',\n",
       " 'rolled',\n",
       " 'into',\n",
       " 'one',\n",
       " 'complex',\n",
       " 'american',\n",
       " 'icon.',\n",
       " 'and',\n",
       " 'she',\n",
       " 'did',\n",
       " 'it',\n",
       " 'with',\n",
       " 'an',\n",
       " 'authenticity',\n",
       " 'and',\n",
       " 'freshness',\n",
       " 'that',\n",
       " 'was',\n",
       " 'totally',\n",
       " 'endearing.',\n",
       " 'lucy',\n",
       " 'was',\n",
       " 'a',\n",
       " 'star',\n",
       " 'turn',\n",
       " 'for',\n",
       " 'rachel',\n",
       " 'york.',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'it',\n",
       " 'brings',\n",
       " 'a',\n",
       " 'flood',\n",
       " 'of',\n",
       " 'great',\n",
       " 'roles',\n",
       " 'her',\n",
       " 'way',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future.',\n",
       " 'i',\n",
       " 'also',\n",
       " 'hope',\n",
       " 'it',\n",
       " 'brings',\n",
       " 'her',\n",
       " 'an',\n",
       " 'emmy.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(None, p.split(pos[101][0].lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f63372",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(r\"/<>(){}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f15e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b4d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
